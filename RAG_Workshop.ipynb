{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index\n",
      "  Downloading llama_index-0.11.16-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting llama-index-agent-openai<0.4.0,>=0.3.4 (from llama-index)\n",
      "  Downloading llama_index_agent_openai-0.3.4-py3-none-any.whl.metadata (728 bytes)\n",
      "Collecting llama-index-cli<0.4.0,>=0.3.1 (from llama-index)\n",
      "  Downloading llama_index_cli-0.3.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting llama-index-core<0.12.0,>=0.11.16 (from llama-index)\n",
      "  Downloading llama_index_core-0.11.16-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting llama-index-embeddings-openai<0.3.0,>=0.2.4 (from llama-index)\n",
      "  Downloading llama_index_embeddings_openai-0.2.5-py3-none-any.whl.metadata (686 bytes)\n",
      "Collecting llama-index-indices-managed-llama-cloud>=0.3.0 (from llama-index)\n",
      "  Downloading llama_index_indices_managed_llama_cloud-0.4.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index)\n",
      "  Downloading llama_index_legacy-0.9.48.post3-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting llama-index-llms-openai<0.3.0,>=0.2.10 (from llama-index)\n",
      "  Downloading llama_index_llms_openai-0.2.11-py3-none-any.whl.metadata (649 bytes)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.3.0,>=0.2.0 (from llama-index)\n",
      "  Downloading llama_index_multi_modal_llms_openai-0.2.2-py3-none-any.whl.metadata (678 bytes)\n",
      "Collecting llama-index-program-openai<0.3.0,>=0.2.0 (from llama-index)\n",
      "  Downloading llama_index_program_openai-0.2.0-py3-none-any.whl.metadata (766 bytes)\n",
      "Collecting llama-index-question-gen-openai<0.3.0,>=0.2.0 (from llama-index)\n",
      "  Downloading llama_index_question_gen_openai-0.2.0-py3-none-any.whl.metadata (785 bytes)\n",
      "Collecting llama-index-readers-file<0.3.0,>=0.2.0 (from llama-index)\n",
      "  Downloading llama_index_readers_file-0.2.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting llama-index-readers-llama-parse>=0.3.0 (from llama-index)\n",
      "  Downloading llama_index_readers_llama_parse-0.3.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting nltk>3.8.1 (from llama-index)\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting openai>=1.14.0 (from llama-index-agent-openai<0.4.0,>=0.3.4->llama-index)\n",
      "  Downloading openai-1.51.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.16->llama-index) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.16->llama-index) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.16->llama-index) (3.10.9)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.16->llama-index) (0.6.7)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.12.0,>=0.11.16->llama-index)\n",
      "  Using cached Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.12.0,>=0.11.16->llama-index)\n",
      "  Using cached dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.16->llama-index) (2024.9.0)\n",
      "Requirement already satisfied: httpx in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.16->llama-index) (0.27.2)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\sahaana\\appdata\\roaming\\python\\python311\\site-packages (from llama-index-core<0.12.0,>=0.11.16->llama-index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.16->llama-index) (3.2.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.16->llama-index) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.16->llama-index) (10.2.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.16->llama-index) (2.9.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.16->llama-index) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.16->llama-index) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.16->llama-index) (0.8.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.16->llama-index) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\sahaana\\appdata\\roaming\\python\\python311\\site-packages (from llama-index-core<0.12.0,>=0.11.16->llama-index) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.16->llama-index) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.16->llama-index) (1.14.1)\n",
      "Collecting llama-cloud>=0.0.11 (from llama-index-indices-managed-llama-cloud>=0.3.0->llama-index)\n",
      "  Downloading llama_cloud-0.1.2-py3-none-any.whl.metadata (763 bytes)\n",
      "Requirement already satisfied: pandas in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2.2.3)\n",
      "Collecting beautifulsoup4<5.0.0,>=4.12.3 (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index)\n",
      "  Using cached beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index)\n",
      "  Downloading pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index)\n",
      "  Using cached striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.3.0->llama-index)\n",
      "  Downloading llama_parse-0.5.7-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: click in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>3.8.1->llama-index) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>3.8.1->llama-index) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>3.8.1->llama-index) (2024.9.11)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.16->llama-index) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.16->llama-index) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.16->llama-index) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.16->llama-index) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.16->llama-index) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.16->llama-index) (1.13.1)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.3.0,>=0.2.0->llama-index)\n",
      "  Using cached soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.16->llama-index) (4.6.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.16->llama-index) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.16->llama-index) (1.0.6)\n",
      "Requirement already satisfied: idna in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.16->llama-index) (3.10)\n",
      "Requirement already satisfied: sniffio in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.16->llama-index) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.16->llama-index) (0.14.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.4->llama-index)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.4->llama-index)\n",
      "  Downloading jiter-0.5.0-cp311-none-win_amd64.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.16->llama-index) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.16->llama-index) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.16->llama-index) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.16->llama-index) (2.2.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.16->llama-index) (3.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\sahaana\\appdata\\roaming\\python\\python311\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.12.0,>=0.11.16->llama-index) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.16->llama-index) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.16->llama-index) (3.22.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sahaana\\appdata\\roaming\\python\\python311\\site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2024.2)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\sahaana\\appdata\\roaming\\python\\python311\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.16->llama-index) (24.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sahaana\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (1.16.0)\n",
      "Downloading llama_index-0.11.16-py3-none-any.whl (6.8 kB)\n",
      "Downloading llama_index_agent_openai-0.3.4-py3-none-any.whl (13 kB)\n",
      "Downloading llama_index_cli-0.3.1-py3-none-any.whl (27 kB)\n",
      "Downloading llama_index_core-0.11.16-py3-none-any.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 0.5/1.6 MB 2.8 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.0/1.6 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.6/1.6 MB 2.8 MB/s eta 0:00:00\n",
      "Downloading llama_index_embeddings_openai-0.2.5-py3-none-any.whl (6.1 kB)\n",
      "Downloading llama_index_indices_managed_llama_cloud-0.4.0-py3-none-any.whl (10 kB)\n",
      "Downloading llama_index_legacy-0.9.48.post3-py3-none-any.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   -------------------------- ------------- 0.8/1.2 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.2/1.2 MB 4.6 MB/s eta 0:00:00\n",
      "Downloading llama_index_llms_openai-0.2.11-py3-none-any.whl (12 kB)\n",
      "Downloading llama_index_multi_modal_llms_openai-0.2.2-py3-none-any.whl (5.9 kB)\n",
      "Downloading llama_index_program_openai-0.2.0-py3-none-any.whl (5.3 kB)\n",
      "Downloading llama_index_question_gen_openai-0.2.0-py3-none-any.whl (2.9 kB)\n",
      "Downloading llama_index_readers_file-0.2.2-py3-none-any.whl (38 kB)\n",
      "Downloading llama_index_readers_llama_parse-0.3.0-py3-none-any.whl (2.5 kB)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 0.8/1.5 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 4.2 MB/s eta 0:00:00\n",
      "Using cached beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Using cached dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Downloading llama_cloud-0.1.2-py3-none-any.whl (173 kB)\n",
      "Downloading llama_parse-0.5.7-py3-none-any.whl (10 kB)\n",
      "Downloading openai-1.51.0-py3-none-any.whl (383 kB)\n",
      "Downloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
      "Using cached striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.5.0-cp311-none-win_amd64.whl (191 kB)\n",
      "Using cached soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: striprtf, dirtyjson, soupsieve, pypdf, jiter, distro, deprecated, nltk, beautifulsoup4, openai, llama-index-core, llama-cloud, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-legacy, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 0.28.0\n",
      "    Uninstalling openai-0.28.0:\n",
      "      Successfully uninstalled openai-0.28.0\n",
      "Successfully installed beautifulsoup4-4.12.3 deprecated-1.2.14 dirtyjson-1.0.8 distro-1.9.0 jiter-0.5.0 llama-cloud-0.1.2 llama-index-0.11.16 llama-index-agent-openai-0.3.4 llama-index-cli-0.3.1 llama-index-core-0.11.16 llama-index-embeddings-openai-0.2.5 llama-index-indices-managed-llama-cloud-0.4.0 llama-index-legacy-0.9.48.post3 llama-index-llms-openai-0.2.11 llama-index-multi-modal-llms-openai-0.2.2 llama-index-program-openai-0.2.0 llama-index-question-gen-openai-0.2.0 llama-index-readers-file-0.2.2 llama-index-readers-llama-parse-0.3.0 llama-parse-0.5.7 nltk-3.9.1 openai-1.51.0 pypdf-4.3.1 soupsieve-2.6 striprtf-0.0.26\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-embeddings-huggingface\n",
      "  Downloading llama_index_embeddings_huggingface-0.3.1-py3-none-any.whl.metadata (718 bytes)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.25.1)\n",
      "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-embeddings-huggingface) (0.11.16)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.1 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-embeddings-huggingface) (3.1.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\sahaana\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\sahaana\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.12.2)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.10.9)\n",
      "Collecting minijinja>=1.0 (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface)\n",
      "  Downloading minijinja-2.2.0-cp38-abi3-win_amd64.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (2.0.35)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.0.8)\n",
      "Requirement already satisfied: httpx in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (0.27.2)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\sahaana\\appdata\\roaming\\python\\python311\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (3.2.1)\n",
      "Requirement already satisfied: nltk>3.8.1 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (3.9.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (10.2.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (2.9.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (0.8.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.14.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.38.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (4.45.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.4.1+cu118)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.5.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.14.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.13.1)\n",
      "Requirement already satisfied: click in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (2024.9.11)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (3.1.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.12)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.1.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\sahaana\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.4.6)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.20.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (3.22.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (4.6.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.0.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (0.14.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.3.0)\n",
      "Downloading llama_index_embeddings_huggingface-0.3.1-py3-none-any.whl (8.6 kB)\n",
      "Downloading minijinja-2.2.0-cp38-abi3-win_amd64.whl (762 kB)\n",
      "   ---------------------------------------- 0.0/762.2 kB ? eta -:--:--\n",
      "   ------------- -------------------------- 262.1/762.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 762.2/762.2 kB 2.9 MB/s eta 0:00:00\n",
      "Installing collected packages: minijinja, llama-index-embeddings-huggingface\n",
      "Successfully installed llama-index-embeddings-huggingface-0.3.1 minijinja-2.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index-embeddings-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-llms-huggingface\n",
      "  Downloading llama_index_llms_huggingface-0.3.4-py3-none-any.whl.metadata (840 bytes)\n",
      "Collecting huggingface-hub<0.24.0,>=0.23.0 (from llama-index-llms-huggingface)\n",
      "  Downloading huggingface_hub-0.23.5-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-llms-huggingface) (0.11.16)\n",
      "Collecting text-generation<0.8.0,>=0.7.0 (from llama-index-llms-huggingface)\n",
      "  Using cached text_generation-0.7.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: torch<3.0.0,>=2.1.2 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-llms-huggingface) (2.4.1+cu118)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.37.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (4.45.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\sahaana\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\sahaana\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (4.12.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (3.10.9)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (1.0.8)\n",
      "Requirement already satisfied: httpx in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (0.27.2)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\sahaana\\appdata\\roaming\\python\\python311\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (3.2.1)\n",
      "Requirement already satisfied: nltk>3.8.1 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (3.9.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (10.2.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (2.9.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (0.8.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (1.14.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (1.12)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (3.1.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.37.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (2024.9.11)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.37.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.37.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (0.20.0)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (0.34.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\sahaana\\appdata\\roaming\\python\\python311\\site-packages (from accelerate>=0.26.0->transformers[torch]<5.0.0,>=4.37.0->llama-index-llms-huggingface) (6.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (1.13.1)\n",
      "Requirement already satisfied: click in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (1.4.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (3.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\sahaana\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.42.1->huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (3.22.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (4.6.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (1.0.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch<3.0.0,>=2.1.2->llama-index-llms-huggingface) (1.3.0)\n",
      "Downloading llama_index_llms_huggingface-0.3.4-py3-none-any.whl (11 kB)\n",
      "Downloading huggingface_hub-0.23.5-py3-none-any.whl (402 kB)\n",
      "Using cached text_generation-0.7.0-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: huggingface-hub, text-generation, llama-index-llms-huggingface\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.25.1\n",
      "    Uninstalling huggingface-hub-0.25.1:\n",
      "      Successfully uninstalled huggingface-hub-0.25.1\n",
      "Successfully installed huggingface-hub-0.23.5 llama-index-llms-huggingface-0.3.4 text-generation-0.7.0\n",
      "Collecting llama-index-llms-huggingface-api\n",
      "  Downloading llama_index_llms_huggingface_api-0.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: huggingface-hub<0.24.0,>=0.23.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-llms-huggingface-api) (0.23.5)\n",
      "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-llms-huggingface-api) (0.11.16)\n",
      "Requirement already satisfied: filelock in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface-api) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface-api) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\sahaana\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface-api) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface-api) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface-api) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface-api) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\sahaana\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface-api) (4.12.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (3.10.9)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (1.0.8)\n",
      "Requirement already satisfied: httpx in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (0.27.2)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\sahaana\\appdata\\roaming\\python\\python311\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (3.2.1)\n",
      "Requirement already satisfied: nltk>3.8.1 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (3.9.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (10.2.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (2.9.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (0.8.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (1.14.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (1.13.1)\n",
      "Requirement already satisfied: click in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (2024.9.11)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface-api) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface-api) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface-api) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface-api) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (3.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\sahaana\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.42.1->huggingface-hub<0.24.0,>=0.23.0->llama-index-llms-huggingface-api) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (3.22.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (4.6.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (1.0.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-huggingface-api) (0.14.0)\n",
      "Downloading llama_index_llms_huggingface_api-0.2.0-py3-none-any.whl (5.0 kB)\n",
      "Installing collected packages: llama-index-llms-huggingface-api\n",
      "Successfully installed llama-index-llms-huggingface-api-0.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index-llms-huggingface\n",
    "!pip install llama-index-llms-huggingface-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SAHAANA\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\SAHAANA\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pydantic\\_internal\\_fields.py:132: UserWarning: Field \"model_id\" in DeployedModel has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\SAHAANA\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pydantic\\_internal\\_fields.py:132: UserWarning: Field \"model_name\" in HuggingFaceLLM has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\SAHAANA\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pydantic\\_internal\\_fields.py:132: UserWarning: Field \"model_kwargs\" in HuggingFaceLLM has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\SAHAANA\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pydantic\\_internal\\_fields.py:132: UserWarning: Field \"model_name\" in HuggingFaceInferenceAPI has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\SAHAANA\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pydantic\\_internal\\_fields.py:132: UserWarning: Field \"model_name\" in TextGenerationInference has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from llama_index.core import Document, VectorStoreIndex, PromptTemplate\n",
    "#from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "file_path = 'wine-ratings.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Create documents from the CSV data\n",
    "documents = []\n",
    "for index, row in df.iterrows():\n",
    "    content = \" \".join([f\"{col}: {row[col]}\" for col in df.columns])\n",
    "    #print(content)\n",
    "    documents.append(Document(text=content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory Allocated: 3000.00 MB\n",
      "Memory Reserved: 3000.00 MB\n",
      "Memory Allocated after another tensor: 3000.15 MB\n",
      "Memory Reserved after another tensor: 3002.00 MB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Set the environment variable for memory allocation (if needed)\n",
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:32'\n",
    "\n",
    "def main():\n",
    "    # Ensure CUDA is available\n",
    "    if torch.cuda.is_available():\n",
    "        # Allocate a tensor of appropriate size on GPU\n",
    "        num_elements = (3000 * 1024**2) // 4  # 100 MiB / 4 bytes per element\n",
    "        tensor_gpu = torch.randn(num_elements, device='cuda')\n",
    "\n",
    "        # Check memory allocated\n",
    "        memory_allocated = torch.cuda.memory_allocated()\n",
    "        memory_reserved = torch.cuda.memory_reserved()\n",
    "\n",
    "        print(f\"Memory Allocated: {memory_allocated / (1024**2):.2f} MB\")\n",
    "        print(f\"Memory Reserved: {memory_reserved / (1024**2):.2f} MB\")\n",
    "\n",
    "        # Perform more operations if needed\n",
    "        another_tensor = torch.randn(200, 200, device='cuda')\n",
    "        print(f\"Memory Allocated after another tensor: {torch.cuda.memory_allocated() / (1024**2):.2f} MB\")\n",
    "        print(f\"Memory Reserved after another tensor: {torch.cuda.memory_reserved() / (1024**2):.2f} MB\")\n",
    "\n",
    "    else:\n",
    "        print(\"CUDA is not available.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SAHAANA\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "c:\\Users\\SAHAANA\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:440: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    }
   ],
   "source": [
    "embedding_model = HuggingFaceEmbedding(model_name=\"sentence-transformers/paraphrase-MiniLM-L6-v2\", device=device)\n",
    "\n",
    "# Create a vector store index\n",
    "index = VectorStoreIndex.from_documents(documents, embed_model=embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HuggingFaceLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SAHAANA\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\SAHAANA\\.cache\\huggingface\\hub\\models--HuggingFaceH4--zephyr-7b-alpha. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Downloading shards: 100%|██████████| 8/8 [54:45<00:00, 410.64s/it]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"HuggingFaceH4/zephyr-7b-alpha\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"HuggingFaceH4/zephyr-7b-alpha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = HuggingFaceLLM(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    query_wrapper_prompt=PromptTemplate(\"\\n</s>\\n\\n{query_str}</s>\\n\\n\"),\n",
    "    context_window=3900,\n",
    "    max_new_tokens=256,\n",
    "    generate_kwargs={\"temperature\": 0.7, \"top_k\": 50, \"top_p\": 0.95},\n",
    "    device_map=\"gpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Local LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-llms-ollama\n",
      "  Downloading llama_index_llms_ollama-0.3.3-py3-none-any.whl.metadata (668 bytes)\n",
      "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-llms-ollama) (0.11.16)\n",
      "Collecting ollama>=0.3.0 (from llama-index-llms-ollama)\n",
      "  Downloading ollama-0.3.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (3.10.9)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (2024.9.0)\n",
      "Requirement already satisfied: httpx in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (0.27.2)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\sahaana\\appdata\\roaming\\python\\python311\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (3.2.1)\n",
      "Requirement already satisfied: nltk>3.8.1 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (3.9.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (10.2.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (2.9.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (0.8.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\sahaana\\appdata\\roaming\\python\\python311\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (1.14.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (1.13.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (4.6.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (1.0.6)\n",
      "Requirement already satisfied: idna in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (3.10)\n",
      "Requirement already satisfied: sniffio in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (0.14.0)\n",
      "Requirement already satisfied: click in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (2024.9.11)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (2.2.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (3.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\sahaana\\appdata\\roaming\\python\\python311\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\sahaana\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (3.22.0)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\sahaana\\appdata\\roaming\\python\\python311\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-ollama) (24.1)\n",
      "Downloading llama_index_llms_ollama-0.3.3-py3-none-any.whl (4.7 kB)\n",
      "Downloading ollama-0.3.3-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: ollama, llama-index-llms-ollama\n",
      "Successfully installed llama-index-llms-ollama-0.3.3 ollama-0.3.3\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index-llms-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "#gemma_2b = Ollama(model=\"gemma:2b\", request_timeout=30.0)\n",
    "\n",
    "llm = Ollama(\n",
    "    model=\"llama3\",\n",
    "    request_timeout=600000\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(\"What is the best Cabernet Sauvignon wine in Napa Valley above 94 points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rating of 90 points for both Caymus Napa Valley Cabernet Sauvignons suggests a good quality wine. However, I'm not aware of any information about other Cabernet Sauvignons with ratings above 94 points in Napa Valley. Therefore, it's difficult to determine the best one without more data or specific recommendations.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
